import time
from logic.chat_manager import chat_manager
from model.loader import pipe
from config.instructions import SYSTEM_INSTRUCTIONS
from config.knowledge import UAEMEX_KNOWLEDGE
from logic.utils import normalize_text


def generate_response(user_query):
    if not user_query.strip():
        return "üéì Por favor, escribe tu pregunta sobre tr√°mites UAEMex."

    entrada_simple = [
        "hola", "buenas", "saludos", "hey", "holi", "qu√© tal",
        "holaa", "holaaa", "hey!", "buenas d√≠as", "buenos d√≠as",
        "buenas tardes", "buenos tardes", "buenas noches", "buenos noches",
        "que tal", "qu√© onda", "que onda", "qu√© hubo", "que hubo",
        "qu√© pasa", "que pasa", "saludos cordiales",
        "buen d√≠a", "buen d√≠a a todos", "buenos d√≠as a todos",
        "buenas tardes a todos", "buenas noches a todos",
        "holis", "holla", "hooola", "buen dia", "buenas!", "heyyy"
    ]

    user_query_normalized = normalize_text(user_query.strip())

    if user_query_normalized in [normalize_text(x) for x in entrada_simple]:
        return "üéì ¬°Hola! Por favor, hazme una pregunta espec√≠fica sobre tr√°mites acad√©micos para poder ayudarte mejor."

    unrelated_terms = ["futbol", "pelicula", "musica", "redes sociales"]
    if any(term in user_query_normalized for term in unrelated_terms):
        return "‚ö†Ô∏è Solo respondo preguntas sobre tr√°mites acad√©micos."

    for main_topic, data in UAEMEX_KNOWLEDGE.items():
        if "subtypes" in data:
            for subtype, response in data["subtypes"].items():
                if normalize_text(subtype) in user_query_normalized:
                    return response

    for topic, data in UAEMEX_KNOWLEDGE.items():
        if any(normalize_text(keyword) in user_query_normalized for keyword in data["keywords"]):
            return data["response"]

    context_text = ""
    for msg in chat_manager.get_context():
        prefix = "Usuario: " if msg["role"] == "user" else "Asistente: "
        context_text += f"{prefix}{msg['content']}\n"

    prompt = (
        f"{SYSTEM_INSTRUCTIONS}\n"
        f"{context_text}"
        f"Usuario: {user_query}\n"
        f"Asistente: "
    )

    try:
        output = pipe(
            prompt,
            max_new_tokens=150,
            temperature=0.9,
            top_p=0.8,
            repetition_penalty=1.2,
            do_sample=True
        )
        response = output[0]["generated_text"].strip()

        if "Usuario:" in response:
            response = response.split("Usuario:")[0].strip()
        if "Asistente:" in response:
            response = response.split("Asistente:")[-1].strip()

        if not response.startswith("üéì"):
            response = f"üéì {response}"

        if len(response) > 600 or any(
            phrase in response.lower() for phrase in ["testigo", "celebraron", "fotos", "abrazos"]
        ):
            return (
                "üéì Lo siento, no puedo responder esa pregunta con informaci√≥n confiable. "
                "Por favor intenta con otra consulta o revisa la p√°gina oficial."
            )

        if "$" in response and "pago" not in user_query_normalized and "costo" not in user_query_normalized:
            response += "\n\n‚ÑπÔ∏è Para informaci√≥n financiera exacta, consulta en Control Escolar"

        return response

    except Exception as e:
        print(f"Error: {str(e)}")
        return "üéì Ocurri√≥ un error al generar la respuesta. Intenta de nuevo."


def respond_letra_por_letra(message, chat_history):
    chat_manager.add_message("user", message)
    chat_history = chat_history or []
    chat_history.append({"role": "user", "content": message})

    chat_history.append({"role": "assistant", "content": "Thinking..."})
    yield "", chat_history, ""

    time.sleep(4)

    respuesta = generate_response(message)
    chat_manager.add_message("assistant", respuesta)

    texto_actual = ""
    for letra in respuesta:
        texto_actual += letra
        chat_history[-1]["content"] = texto_actual
        yield "", chat_history, ""
        time.sleep(0.01)

    yield "", chat_history, ""


def set_and_respond(question, chat_history):
    chat_manager.add_message("user", question)
    bot_response = generate_response(question)
    chat_manager.add_message("assistant", bot_response)
    chat_history = chat_history or []
    chat_history.append({"role": "user", "content": question})
    chat_history.append({"role": "assistant", "content": bot_response})
    return "", chat_history, ""